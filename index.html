<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Devin J. Cornell</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/resume.min.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Devin J. Cornell</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="https://storage.googleapis.com/public_data_09324832787/profile_photo_square.png?w=1000&h=&crop=1" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
		<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="https://storage.googleapis.com/public_data_09324832787/cornell-curriculum_vitae.pdf">CV</a>
        </li>
    <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#recentworks">Recent Works</a>
        </li>
		<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#pythonpackages">Python Packages</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#blogposts">Blog Posts</a>
        </li>
        <!--<li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#experience">Experience</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#education">Education</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#skills">Skills</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#interests">Interests</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#awards">Awards</a>
        </li>-->
      </ul>
    </div>
  </nav>

  <div class="container-fluid p-0" style="background-image: url('https://storage.googleapis.com/public_data_09324832787/network_colombian_politicians.png'); background-repeat: no-repeat; background-position: right top;">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
      <div class="w-100">
        <h1 class="mb-0">Devin J. Cornell
          <!--<span class="text-primary">Cornell</span>-->
        </h1>
        <div class="subheading mb-5">Sociology PhD Student at Duke University<br/>
          <a>devin.cornell [at] duke.edu</a>
        </div>
        <p class="lead mb-5">I use computational methods to study cultural processes through <br/>which organizations produce and are shaped by meaning.</p>
        <div class="social-icons">
          <a href="https://github.com/devincornell">
            <i class="fab fa-github"></i>
          </a>
          <a href="https://twitter.com/Devin_Cornell">
            <i class="fab fa-twitter"></i>
          </a>
        </div>
      </div>
    </section>
    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="recentworks">
      <div class="w-100">
        <h2 class="mb-5">Recent Work</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Discursive Fields and Intra-party Influence in Colombian Politics</h3>
            <div class="subheading mb-3">MA Thesis Committee: John W. Mohr, Maria S. Charles, Verta Taylor</div>
            <p><a href="https://escholarship.org/uc/item/85w8h6qx">Thesis on UC Santa Barbara eScholarship</a></p>
            <p>When are politicians influential in shifting party discourse? This study explores how same-party politicians influence one another, and how this influence leads to changes to a party's larger discourse. I suggest that the extent to which politicians are able to influence other party politicians depends on how their messages situate them within the party’s discursive field. I further suggest that certain messages are particularly influential when distinctive within a given time period. To assess this effect, I use a case study of just under 1 million Tweets from politicians in the Colombian political party Centro Democrático from 2015-2017. I use topic modeling and network analysis to measure influence within a dynamic discursive field, and a genetic learning algorithm to identify types of messages, as topics, which constitute the field under which we observe the strongest linkage between field position and influence. I find that politicians are influential when posting about current events and when creating symbolic distinctions which are central to the party ideology - in the case of Centro Democrático, distinctions between the concept of peace itself and the peace process developing in Colombia. These results suggest that the discursive field can be a powerful tool for analysis of influence and political discourse.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary"></span>
          </div>
        </div>


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">School, Studying, and Smarts: Gender Stereotypes and Education Across 80 Years of American Print Media, 1930-2009</h3>
            <div class="subheading mb-3">Andrei Boutyline, Alina Arseniev-Koehler, Devin Cornell</div>
			  <p><a href="https://osf.io/preprints/socarxiv/bukdg">Working Paper on SocArXiv</a></p>
			  <p>Gender stereotypes have important consequences for boys’ and girls’ academic outcomes. In this article, we apply computational word embeddings to a 200-million-word corpus of American print media (1930-2009) to examine how these stereotypes changed as women’s educational attainment caught up with and eventually surpassed men’s. This transformation presents a rare opportunity to observe how stereotypes change alongside the reversal of an important pattern of stratification. We track six stereotypes that prior work has linked to academic outcomes. Our results suggest that stereotypes of socio-behavioral skills and problem behaviors—attributes closely tied to the core stereotypical distinction between women as communal and men as agentic—remained unchanged. The other four stereotypes, however, became increasingly gender-polarized: as women’s academic attainment increased, school and studying gained increasingly feminine associations, whereas both intelligence and unintelligence gained increasingly masculine ones. Unexpectedly, we observe that trends in the gender associations of intelligence and studying are near-perfect mirror opposites, suggesting that they may be connected. Overall, the changes we observe appear consistent with contemporary theoretical accounts of the gender system that argue that it persists partly because surface stereotypes shift to reinterpret social change in terms of a durable hierarchical distinction between men and women.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary"></span>
          </div>
        </div>
		  


      </div>

    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="pythonpackages">
      <div class="w-100">
        <h2 class="mb-5">Python Packages</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">DocTable</h3>
            <div class="subheading mb-3">Python package for parsing, storing, and accessing text documents and models for large scale text analysis.</div>
            <p><a href="https://devincornell.github.io/doctable/">Website</a></p>
            <p><a href="https://github.com/devincornell/doctable/">GitHub Project</a></p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary"></span>
          </div>
        </div>
		  
		    <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">EasyText</h3>
            <div class="subheading mb-3">Command-line tool for text analysis.</div>
			      <p>Create topic models, run sentiment analysis, count named entities, and extract subject-verb-object triplets from the command line.</p>
			      <a href="https://github.com/devincornell/easytext/">GitHub Project</a>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary"></span>
          </div>
        </div>

      </div>

    </section>

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="blogposts">
      <div class="w-100">
        <h2 class="mb-5">Blog Posts</h2>
        
    <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
        <div class="resume-content">
            <h3 class="mb-0"><a data-toggle="collapse" href="#reflections_on_workshops" role="button" aria-expanded="false" aria-controls="reflections_on_workshops">Reflections on creating workshops on text analysis</a></h3>
            <div class="subheading mb-3">Jan 12, 2021</div>
            <p>Last month I did a workshop on text analysis in Python for a new computational social science group that several of us started at Duke Sociology (<a href="https://github.com/devincornell/workshops/tree/master/duke_css_workshop_11-08-21">workshop materials</a>). As I created the workshop materials, I had two thoughts: <strong>(1)</strong> most text analysis projects require essentially the same set of steps. The key is to come up with a system and design pattern that works for you. <strong>(2)</strong> There aren’t many new algorithms for text analysis in the social sciences. Most algorithms we've picked up are simply more efficient or slightly different variations of very old algorithms. </p>
            <p><a data-toggle="collapse" href="#reflections_on_workshops" role="button" aria-expanded="false" aria-controls="reflections_on_workshops">Expand full post...</a></p>
            <div class="collapse" id="reflections_on_workshops">
                <p><strong><em>Most text analysis projects require the same steps.</em></strong> By this I mean that most projects require the same or similar boilerplate tasks: preprocessing might involve fixing spelling issues or removing artifacts from original texts; tokenization involves some decisions about which tokens to include, how to deal with named entities, stopword removal, or hyphenation collapsing; document representation storage involves placing the parsed dataset into a database (plug for my package doctable), spreadsheet, pickled file, or some other storage medium that can be accessed. Then an algorithm operates on those document representations to create models, which are again stored in a database or other file for creating visualizations or running statistical models. There may be more aspects to this: hand-coding, metadata analysis, etc tend to be pretty important - but the exceptions are rare.</p>
<p>The point of learning these tools is to develop a series of design patterns. Most of us (speaking to social scientists here) are not software engineers, nor have we ever even been paid to write code that someone else will read or use. If we were, we would know that design patterns in code are all about predictability. Despite the incredibly large range of possible algorithm designs that could be used, the software engineer seeks to be consistent: consistent project structure, consistent design architecture, and even consistent use of syntax for basics like loops and conditionals. Someone has to read that code, so the goal is to make it as easily understood as possible. For us, we are (often) the only ones to read our code. So learning to write research code is about developing our way of doing the same boilerplate tasks and organizing projects in a way that we can recognize easily in the future.</p>
<p><strong><em>There aren’t that many new tools for text analysis in the social sciences.</em></strong> Let'’'s start with an easy one: Latent Dirichlet Analysis (LDA). This one algorithm spurred on a (perceived) revolution of social scientists doing text analysis for interpretation. It hit everywhere: sociology (see this <a href="https://www.sciencedirect.com/journal/poetics/vol/41/issue/6">Poetics special issue</a>), corpus linguistics, and the digital humanities especially. Right now, Word2Vec is <em>HOT</em>. Same deal, different algorithm. Now, I’m not against this: in fact, I’ve used both of these tools in research projects, and I think they can be incredibly useful and provide important insights. My argument is not that they are not useful – only that they are not particularly novel in the ways that social scientists use them.</p>
<p>While LDA has by become by-far the most popular topic modeling algorithm, it does pretty much the same thing as its matrix factorization equivalent Nonnegative Matrix Factorization (NMF). They both start with the same model of the texts: documents are bags of words represented as rows in a document-term matrix. NMF is similar to Singular Value Decomposition (SVD) except that it works on matrices with only positive entries. The thing is, NMF is really old. For whatever reason, it was LDA that spurred interest in topic modeling for the social sciences. Same thing goes for word embeddings. While Word2Vec became hugely possible, subsequent works showed that a simple Pointwise Mutual Information (PMI) calculation based on word frequency with SVD could produce results similar to those from Word2Vec, but PMI-SVD has been around for a really long time. With the exception of parsetree and named entity extraction, I’m not totally convinced that we’ve seen anything new that really changes the way we can analyze texts.</p>
<p>If most text analysis pipelines are very similar and we’re using basically the same tools as we’ve had for the last few decades, where does that leave text analysis researchers? It leaves us with substance. The fact that these algorithms are so readily available and we have so many tools for working with texts means that we can focus less on methods and more on substantive analyses. In my opinion, the value in doing computational text analysis is more than the cool factor: we can answer classical questions that were difficult to answer before. In an increasingly digital society the study of digital texts has never been so important. We just have to be willing to ask the right questions before we pick up new tools.</p>
            </div>
        </div>
        <div class="resume-date text-md-right">
            <span class="text-primary"></span>
        </div>
    </div>
    

    <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
        <div class="resume-content">
            <h3 class="mb-0"><a data-toggle="collapse" href="#opened_nss_docs" role="button" aria-expanded="false" aria-controls="opened_nss_docs">New repo for cleaned NSS documents</a></h3>
            <div class="subheading mb-3">Dec 3, 2019</div>
            <p>I created a <a href="https://github.com/devincornell/nssdocs">public GitHub repo</a> to share a cleaned version of the US National Security Strategy documents in plain text. It is a nice dataset to use for text analysis demos, and you can use the <a href="https://github.com/devincornell/nssdocs/blob/master/example_download.py"><code>download_nss</code> function</a> to download the docs from the public repo directly in your code.</p>
            <p><a data-toggle="collapse" href="#opened_nss_docs" role="button" aria-expanded="false" aria-controls="opened_nss_docs">Expand full post...</a></p>
            <div class="collapse" id="opened_nss_docs">
                <p>I generated these by copy/pasting the pdf text into plain text and doing some cleaning like special character conversion and some spell-checking. Paragraphs in the text are separated by two newlines, and all paragraphs appear on the same line.</p>
<p>The choice of NSS documents was motivated by one of my all-time favorite articles co-authored by my former advisor John Mohr, Robin Wagner-Pacifici, and Ronald Breiger. In addition to the documents analyzed in that piece, I also copy/pasted text from the Trump 2017 NSS document. Each presidential administration since 1987 is required to produce at least one document per term, so you can easily compare the documents by administration or party. </p>
<p>Mohr, J. W., Wagner-Pacifici, R., and Breiger, R. L. (2015). <em>Toward a computational hermeneutics.</em> Big Data and Society, (July–December), 1–8. (<a href="https://journals.sagepub.com/doi/full/10.1177/2053951715613809">link</a>)</p>
            </div>
        </div>
        <div class="resume-date text-md-right">
            <span class="text-primary"></span>
        </div>
    </div>
    

    <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
        <div class="resume-content">
            <h3 class="mb-0"><a data-toggle="collapse" href="#ucsb_instructional_development_grant" role="button" aria-expanded="false" aria-controls="ucsb_instructional_development_grant">UCSB Instructional Development Grant</a></h3>
            <div class="subheading mb-3">April 11, 2019</div>
            <p>John Mohr and I recently received a grant for undergraduate instructional development aimed at creating a tool for non-programmers to run and analyze LDA and NMF topic models on a provided set of texts. We chose to make this tool accessable to non-coders so that it can be integrated into general sociology courses where most students have very little technical experience. The tool generates topic-token and document-topic distributions as an excel spreadsheet, allowing students to run analyses and generate figures from within an interface they may be familiar with. The tool uses a command-line interface and can be installed using the command <a href="https://pypi.org/project/easytext/"><code>pip install easytext</code></a> (<a href="https://github.com/devincornell/easytext">github repo</a>).</p>
            <p><a data-toggle="collapse" href="#ucsb_instructional_development_grant" role="button" aria-expanded="false" aria-controls="ucsb_instructional_development_grant">Expand full post...</a></p>
            <div class="collapse" id="ucsb_instructional_development_grant">
                <p>The command line interface is particularly focused on generating spreadsheets that students can then view and manipulate in a spreadsheet program like Excel or LibreOffice. Students can perform interpretive analysis by going between EasyText output spreadsheets and the original texts, or feed the output into a quantitative analysis program like R or Stata. The program supports features for simple word counting, noun phrase detection, Named Entity Recognition, noun-verb pair detection, entity-verb detection, prepositional phrase extraction, basic sentiment analysis, topic modeling, and the GloVe word embedding algorithm.</p>
<p>While there are debates about the role of topic modeling and other algorithmic approaches to text analysis requiring interpretation, our undergraduate students have shown enthusiasm and diligence in considering the limitations and strengths of such tools (see an example of a student I mentored). In many ways, their experiences with text analysis algorithms have forced them to think beyond the familiarity of p-values and confidence intervals to establish different kinds of patterns in the social world – ones that may be partially out-of-reach with classical sociological research methods. And in this process, they are forced to consider the promises and pitfalls of using these algorithms for analyses.</p>
<p>See the <a href="https://github.com/devincornell/easytext/blob/master/README.md">README</a> and <a href="https://github.com/devincornell/easytext/blob/master/docs/Command_Reference.md">Command Reference</a> pages for usage examples.</p>
<p>As an example use case, consider a time when you have a spreadsheet of document names and texts called “mytextdata.xls”. Let’s assume that the column name of document names is “title” and the column of texts is simply “text”. To run a topic model of this text data with 10 topics that outputs to “mytopicmodel.xls”, we would use the following command:</p>
<pre><code>python -m easytext topicmodel -n 10 mytextdata.xls --doclabelcol "title" --textcol "text" mytopicmodel.xls
</code></pre>
<p>The topic model output spreadsheet contains four sheets: <code>doc_topic</code>, <code>topic_words</code>, <code>doc_summary</code>, and <code>topic_summary</code>. <img alt="easytext spreadsheet example" src="https://storage.googleapis.com/public_data_09324832787/easytext_example_spreadsheet.png" /></p>
<p>While <code>doc_topic</code> contains rows as documents and columns as topic probabilities and <code>topic_words</code> contains topics as words and word probabilities as columns, the <code>doc_summary</code> and <code>topic_summary</code> sheets are meant to assist with interpretation; the topics most closely associated with each document and the words most closely associated with each topic, respectively.</p>
<p>Any topic model interpretation of course relies on referring back to the text of the original documents themselves, but this spreadsheet is designed to help with the process of linking the statistical topic model with the content and form of texts.</p>
<p>Further documentation is needed to push this into an instructional tool, but this is a good first step towards that end.</p>
            </div>
        </div>
        <div class="resume-date text-md-right">
            <span class="text-primary"></span>
        </div>
    </div>
    
      </div>

    </section>
    

	<!--
    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="education">
      <div class="w-100">
        <h2 class="mb-5">Education</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">University of Colorado Boulder</h3>
            <div class="subheading mb-3">Bachelor of Science</div>
            <div>Computer Science - Web Development Track</div>
            <p>GPA: 3.23</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">August 2006 - May 2010</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
          <div class="resume-content">
            <h3 class="mb-0">James Buchanan High School</h3>
            <div class="subheading mb-3">Technology Magnet Program</div>
            <p>GPA: 3.56</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">August 2002 - May 2006</span>
          </div>
        </div>

      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="skills">
      <div class="w-100">
        <h2 class="mb-5">Skills</h2>

        <div class="subheading mb-3">Programming Languages &amp; Tools</div>
        <ul class="list-inline dev-icons">
          <li class="list-inline-item">
            <i class="fab fa-html5"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-css3-alt"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-js-square"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-angular"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-react"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-node-js"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-sass"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-less"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-wordpress"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-gulp"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-grunt"></i>
          </li>
          <li class="list-inline-item">
            <i class="fab fa-npm"></i>
          </li>
        </ul>

        <div class="subheading mb-3">Workflow</div>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-check"></i>
            Mobile-First, Responsive Design</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            Cross Browser Testing &amp; Debugging</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            Cross Functional Teams</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            Agile Development &amp; Scrum</li>
        </ul>
      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="interests">
      <div class="w-100">
        <h2 class="mb-5">Interests</h2>
        <p>Apart from being a web developer, I enjoy most of my time being outdoors. In the winter, I am an avid skier and novice ice climber. During the warmer months here in Colorado, I enjoy mountain biking, free climbing, and kayaking.</p>
        <p class="mb-0">When forced indoors, I follow a number of sci-fi and fantasy genre movies and television shows, I am an aspiring chef, and I spend a large amount of my free time exploring the latest technology advancements in the front-end web development world.</p>
      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="awards">
      <div class="w-100">
        <h2 class="mb-5">Awards &amp; Certifications</h2>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Google Analytics Certified Developer</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Mobile Web Specialist - Google Certification</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1<sup>st</sup>
            Place - University of Colorado Boulder - Emerging Tech Competition 2009</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1<sup>st</sup>
            Place - University of Colorado Boulder - Adobe Creative Jam 2008 (UI Design Category)</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            2<sup>nd</sup>
            Place - University of Colorado Boulder - Emerging Tech Competition 2008</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1<sup>st</sup>
            Place - James Buchanan High School - Hackathon 2006</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            3<sup>rd</sup>
            Place - James Buchanan High School - Hackathon 2005</li>
        </ul>
      </div>
    </section>
	-->

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/resume.min.js"></script>

</body>

</html>
